{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authorized-tiffany",
   "metadata": {},
   "source": [
    "# BERT is not all you need - at least in LegalTech - draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-netscape",
   "metadata": {},
   "source": [
    "This short notebook was inspired by post https://www.linkedin.com/feed/update/urn:li:activity:6782558075611037697/ and this article / mater thesis: https://arxiv.org/pdf/2103.11792.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "color-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lzma\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_accuracy_f1_score_for_set(x, y, name):\n",
    "    x_test_vectorized = vectorizer.transform(x)\n",
    "    y_pred = model.predict(x_test_vectorized)\n",
    "    \n",
    "    acc = sum(y == y_pred)/len(y)\n",
    "    print(f\"Accuracy for {name} set {acc}\")\n",
    "    score = f1_score(y, y_pred,  pos_label='majority') \n",
    "    print(f\"F1 for {name} set {score}\")\n",
    "\n",
    "def get_number_of_opinions(row):\n",
    "    try:\n",
    "        return len(row.casebody[\"data\"][\"opinions\"])\n",
    "    except AttributeError:\n",
    "        print(row)\n",
    "        return None\n",
    "    \n",
    "def get_label_and_text(row):\n",
    "    try:\n",
    "        return [(row[0], i[\"type\"], i[\"text\"]) for i in row[1].casebody[\"data\"][\"opinions\"]]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-savage",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amazing-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in [\"./data_legal/Arkansas-20200302-text//data/data.jsonl.xz\",\n",
    "             \"./data_legal/Illinois-20200302-text///data/data.jsonl.xz\",\n",
    "             \"./data_legal/New Mexico-20200302-text///data/data.jsonl.xz\",\n",
    "             \"./data_legal/North Carolina-20200416-text///data/data.jsonl.xz\"]:\n",
    "    with lzma.open(file, 'rb') as f:\n",
    "        x = f.read()\n",
    "    data.extend([json.loads(j) for j in x.decode('utf-8').splitlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emerging-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seeing-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"length\"] =  [get_number_of_opinions(i[1]) for i in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "considered-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0, 5, 8, 7, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"length\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases = []\n",
    "for row in data.iterrows():\n",
    "    all_cases.extend(get_label_and_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "palestinian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(all_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"case_id\", \"label\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18650"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[\"label\"]=='dissent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expected-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>majority</td>\n",
       "      <td>OPINION OF THE COIÍRT. This is an action of de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>majority</td>\n",
       "      <td>OPINION OP THE COURT. This is an appeal from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>majority</td>\n",
       "      <td>CROSS, Judge.\\nThe record in this case shows t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>majority</td>\n",
       "      <td>W. H.“Dub” Arnold, Chief Justice.\\nThis is a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>rehearing</td>\n",
       "      <td>SUPPLEMENTAL OPINION ON DENIAL OF REHEARING\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388634</th>\n",
       "      <td>358814</td>\n",
       "      <td>majority</td>\n",
       "      <td>PER CURIAM.\\nJustice EDMUNDS took no part in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388635</th>\n",
       "      <td>358815</td>\n",
       "      <td>majority</td>\n",
       "      <td>HUDSON, Justice.\\nHere we are asked to determi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388636</th>\n",
       "      <td>358816</td>\n",
       "      <td>majority</td>\n",
       "      <td>1. State’s Motion for Temporary Stay (COA14-41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388637</th>\n",
       "      <td>358817</td>\n",
       "      <td>majority</td>\n",
       "      <td>1. State’s Motion for Temporary Stay (COA15-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388638</th>\n",
       "      <td>358818</td>\n",
       "      <td>majority</td>\n",
       "      <td>ORDER\\nThis matter is before this Court on def...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388639 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_id      label                                               text\n",
       "0             0   majority  OPINION OF THE COIÍRT. This is an action of de...\n",
       "1             1   majority  OPINION OP THE COURT. This is an appeal from t...\n",
       "2             2   majority  CROSS, Judge.\\nThe record in this case shows t...\n",
       "3             3   majority  W. H.“Dub” Arnold, Chief Justice.\\nThis is a c...\n",
       "4             3  rehearing  SUPPLEMENTAL OPINION ON DENIAL OF REHEARING\\nW...\n",
       "...         ...        ...                                                ...\n",
       "388634   358814   majority  PER CURIAM.\\nJustice EDMUNDS took no part in t...\n",
       "388635   358815   majority  HUDSON, Justice.\\nHere we are asked to determi...\n",
       "388636   358816   majority  1. State’s Motion for Temporary Stay (COA14-41...\n",
       "388637   358817   majority  1. State’s Motion for Temporary Stay (COA15-15...\n",
       "388638   358818   majority  ORDER\\nThis matter is before this Court on def...\n",
       "\n",
       "[388639 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-excellence",
   "metadata": {},
   "source": [
    "# Prepare smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ongoing-third",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "majority                                     358489\n",
       "dissent                                       18650\n",
       "concurrence                                    7765\n",
       "concurring-in-part-and-dissenting-in-part      2060\n",
       "rehearing                                      1663\n",
       "on-motion-to-strike-cost-bill                     4\n",
       "on-the-merits                                     4\n",
       "remittitur                                        3\n",
       "unanimous                                         1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naked-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_check = data[data.label.isin([\"majority\", \"dissent\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "robust-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_samples = data_to_check[data_to_check[\"label\"] == \"majority\"].sample(30000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heated-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampled = pd.concat((majority_samples, data[data[\"label\"] == \"dissent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attempted-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_check = data_sampled.drop_duplicates(\"case_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "static-progress",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "majority    30000\n",
       "dissent     16198\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_check.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-notification",
   "metadata": {},
   "source": [
    "# \"Experiment\" on the original opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intensive-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_sampled.text, \n",
    "                                                    data_sampled.label, \n",
    "                                                    stratify=data_sampled.label,\n",
    "                                                    random_state=123, \n",
    "                                                    test_size=0.3\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prostate-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test, \n",
    "                                                    y_test, \n",
    "                                                    stratify=y_test,\n",
    "                                                    random_state=123, \n",
    "                                                    test_size=0.5\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promotional-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34055, 7297, 7298)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sunrise-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.lower().split(),\n",
    "                             preprocessor=lambda x:  x.lower().split(),\n",
    "                            analyzer=lambda x:  x.lower().split(),\n",
    "                            stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "correct-connectivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_vectorized = vectorizer.fit_transform(x_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "freelance-documentary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/environments/contentyze_model_service_python3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:51:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=20, num_parallel_tree=1,\n",
       "              random_state=123, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=123)\n",
    "model.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-awareness",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "republican-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test set 0.9946553378100589\n",
      "F1 for test set 0.9956700344176751\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy_f1_score_for_set(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accessible-defense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for valid set 0.9950671416826528\n",
      "F1 for valid set 0.9960053262316911\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy_f1_score_for_set(x_valid, y_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-keyboard",
   "metadata": {},
   "source": [
    "### Words that are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fatty-ordering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_ids = np.where(model.feature_importances_ > 0.02)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "endless-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {k:v for v, k in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "primary-central",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concur.\n",
      "dissenting:\n",
      "i\n",
      "majority\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "for i in words_ids:\n",
    "    print(vocab[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-small",
   "metadata": {},
   "source": [
    "# \"Experiment\" on the truncated opinions (word \"dissenting\" is removed from the beginning of opinion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-helping",
   "metadata": {},
   "source": [
    "### Removing \"dissenting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pacific-improvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dissent     17824\n",
       "majority       18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sampled[data_sampled[\"text\"].apply(lambda x: \"dissenting\" in x[:100] if x else False)].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "induced-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampled[\"truncated_text\"] = data_sampled[\"text\"].apply(lambda x: x[100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-layer",
   "metadata": {},
   "source": [
    "### And the same procedure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cooked-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_sampled.truncated_text, \n",
    "                                                    data_sampled.label, \n",
    "                                                    stratify=data_sampled.label,\n",
    "                                                    random_state=123, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "several-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test, \n",
    "                                                    y_test, \n",
    "                                                    stratify=y_test,\n",
    "                                                    random_state=123, \n",
    "                                                    test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "contemporary-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.lower().split(),\n",
    "                             preprocessor=lambda x:  x.lower().split(),\n",
    "                            analyzer=lambda x:  x.lower().split(),\n",
    "                            stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pacific-demonstration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_vectorized = vectorizer.fit_transform(x_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "upset-nowhere",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/environments/contentyze_model_service_python3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:53:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=20, num_parallel_tree=1,\n",
       "              random_state=123, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=123)\n",
    "model.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "choice-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_f1_score_for_set(x, y, name):\n",
    "    x_test_vectorized = vectorizer.transform(x)\n",
    "    y_pred = model.predict(x_test_vectorized)\n",
    "    \n",
    "    acc = sum(y == y_pred)/len(y)\n",
    "    print(f\"Accuracy for {name} set {acc}\")\n",
    "    score = f1_score(y, y_pred,  pos_label='majority') \n",
    "    print(f\"F1 for {name} set {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-nomination",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fresh-leave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test set 0.9693024530629025\n",
      "F1 for test set 0.9752977503308337\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy_f1_score_for_set(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "about-netscape",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for valid set 0.9693066593587284\n",
      "F1 for valid set 0.9753629564452265\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy_f1_score_for_set(x_valid, y_valid, \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-hebrew",
   "metadata": {},
   "source": [
    "### Important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "living-consciousness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_ids = np.where(model.feature_importances_ > 0.02)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "unexpected-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {k:v for v, k in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "average-opinion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concur.\n",
      "i\n",
      "majority\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "for i in words_ids:\n",
    "    print(vocab[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
